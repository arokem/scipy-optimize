<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8">
    <meta name="generator" content="pandoc">
    <title>Introduction – models and why we like them</title>
    <link rel="shortcut icon" type="image/x-icon" href="/favicon.ico" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <link rel="stylesheet" type="text/css" href="css/bootstrap/bootstrap.css" />
    <link rel="stylesheet" type="text/css" href="css/bootstrap/bootstrap-theme.css" />
    <link rel="stylesheet" type="text/css" href="css/swc.css" />
    <meta charset="UTF-8" />
    <!-- HTML5 shim, for IE6-8 support of HTML5 elements -->
    <!--[if lt IE 9]>
      <script src="http://html5shim.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->
  </head>
  <body class="lesson">
    <div class="container card">
      <div class="banner">
      
      </div>
      <article>
      <div class="row">
        <div class="col-md-10 col-md-offset-1">
                    <h1 class="title">Introduction – models and why we like them</h1>
          <section class="objectives panel panel-warning">
<div class="panel-heading">
<h2 id="learning-objectives"><span class="glyphicon glyphicon-certificate"></span>Learning Objectives</h2>
</div>
<div class="panel-body">
<ul>
<li>Learners can define what a model is.</li>
<li>Learners can define model parameters and model fitting.</li>
<li>Learners can restate the benefits of modeling</li>
<li>Learners can explain the utility of modeling applied to their data.</li>
</ul>
</div>
</section>
<p>To understand why you would want to fit models in your research, let’s first consider an experiment in visual neuroscience (this experiment was conducted by Ariel Rokem in collaboration with <a href="http://www.landaulab.com/ayelet-landau.html">Ayelet Landau</a>, and the data was collected by Ayelet while she was at the Ernst Strüngmann Institute in Frankfurt).</p>
<p>In these experiments, participants viewed a stimulus that contained a grating. In each trial of the experiment two gratings were displayed in quick succession.</p>
<p>The first grating might look something like this:</p>
<figure>
<img src="img/surrounded.png" alt="Surrounded grating" /><figcaption>Surrounded grating</figcaption>
</figure>
<p>While the second would <em>always</em> look like this:</p>
<figure>
<img src="img/comparison.png" alt="Comparison grating" /><figcaption>Comparison grating</figcaption>
</figure>
<p>In each trial of the experiment, participants had to say which of the gratings (the first grating, or the second grating) had higher contrast.</p>
<aside class="callout panel panel-info">
<div class="panel-heading">
<h2 id="contrast-and-surround-suppression"><span class="glyphicon glyphicon-pushpin"></span>Contrast and surround suppression</h2>
</div>
<div class="panel-body">
<p>While our visual system is not particulary good at identifying and discriminating the precise luminance or brightness of a stimulus, it is very sensitive to small changes in contrast. That is, to small <em>differences</em> in luminance across the image. Grating stimuli, like the one we used, are often used in vision science to probe this sensitivity. This is a way for us to measure the effects of the presence of a surround on contrast perception. For example, it is well known that the relative orientation of the surround affects the degree to which the surround reduces the perceived contrast of the central patch. If the surrounding grating is parallel to the stimulus (as in the case shown above; also sometimes called ‘co-linear’), it has a stronger effect on the perceived contrast (the contrast appears lower, just by virtue of the presence of the grating!). If the surrounding grating is orthogonal to the central patch, the effect is still there, but it is much weaker.</p>
<p>If you are wondering why we are interested in surround suppression in the first place, you can find some of our papers using these measurements on <a href="http://arokem.org/publications">my website</a>. For example, in <a href="https://doi.org/10.1523/JNEUROSCI.6158-09.2010">one study</a>, we found that this measurement tells us about differences in brain chemistry between healthy people, and patients with schizophrenia.</p>
</div>
</aside>
<p>Let’s look at the experimental data from one participant. We have two files from this one subject in csv files, <code>scipy-optimize-data/ortho.csv</code> and <code>scipy-optimize-data/para.csv</code>. As their names suggest they come from two different runs of the experiment: one in which the surrounding stimulus was oriented in the parallel orientation relative to the center stimulus and one in which the surrounding stimulus was orthogonal to the center stimulus. The files contain three columns: contrast1 is the contrast in the first interval, contrast2 is the contrast in the second interval and answer is what the participant thought had higher contrast. We will use the Pandas function <code>pd.read_csv</code> to read the data into a <a href="https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.html">DataFrame</a>:</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb1-1" data-line-number="1"><span class="im">import</span> pandas <span class="im">as</span> pd</a>
<a class="sourceLine" id="cb1-2" data-line-number="2">ortho <span class="op">=</span> pd.read_csv(<span class="st">&#39;../data/ortho.csv&#39;</span>)</a>
<a class="sourceLine" id="cb1-3" data-line-number="3">para <span class="op">=</span> pd.read_csv(<span class="st">&#39;../data/para.csv&#39;</span>)</a></code></pre></div>
<p>We will not explain in much detail what Pandas does, except to mention that the DataFrame that was created contains columns of data that can be addressed by their name. For example, <code>ortho['contrast1']</code> contains a sequence of all the contrasts shown during interval 1.</p>
<p>If you take a look at the data you will see that the contrast in the second interval was always 0.3 (30% contrast). That’s because this stimulus served as a reference stimulus, to help participants as an anchor. In other experiments, we also varied that, but, for the purpose for our analysis here, we can safely ignore that column altogether and only look at the contrast in the first interval. Let’s take a look at the data. First, we are just going to plot the raw data as it is. We will consider the contrasts as our independent variable, and the responses as the dependent variables.</p>
<div class="sourceCode" id="cb2"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb2-1" data-line-number="1"></a>
<a class="sourceLine" id="cb2-2" data-line-number="2"><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</a>
<a class="sourceLine" id="cb2-3" data-line-number="3"><span class="im">import</span> numpy <span class="im">as</span> np</a>
<a class="sourceLine" id="cb2-4" data-line-number="4"><span class="op">%</span>matplotlib inline</a>
<a class="sourceLine" id="cb2-5" data-line-number="5">fig, ax <span class="op">=</span> plt.subplots(<span class="dv">1</span>)</a>
<a class="sourceLine" id="cb2-6" data-line-number="6"><span class="co"># We apply a small vertical jitter to each point, just to show that there are</span></a>
<a class="sourceLine" id="cb2-7" data-line-number="7"><span class="co"># multiple points at each location:</span></a>
<a class="sourceLine" id="cb2-8" data-line-number="8">ax.plot(ortho[<span class="st">&#39;contrast1&#39;</span>], ortho[<span class="st">&#39;answer&#39;</span>] <span class="op">+</span></a>
<a class="sourceLine" id="cb2-9" data-line-number="9">        np.random.randn(<span class="bu">len</span>(ortho)) <span class="op">*</span> <span class="fl">0.02</span> , <span class="st">&#39;*&#39;</span>)</a>
<a class="sourceLine" id="cb2-10" data-line-number="10">ax.plot(para[<span class="st">&#39;contrast1&#39;</span>], para[<span class="st">&#39;answer&#39;</span>] <span class="op">+</span></a>
<a class="sourceLine" id="cb2-11" data-line-number="11">        np.random.randn(<span class="bu">len</span>(para)) <span class="op">*</span> <span class="fl">0.02</span> , <span class="st">&#39;+&#39;</span>)</a>
<a class="sourceLine" id="cb2-12" data-line-number="12">ax.set_ylim([<span class="fl">0.9</span>, <span class="fl">2.1</span>])</a>
<a class="sourceLine" id="cb2-13" data-line-number="13">ax.set_xlabel(<span class="st">&#39;Contrast 1&#39;</span>)</a>
<a class="sourceLine" id="cb2-14" data-line-number="14">ax.set_ylabel(<span class="st">&#39;Which stimulus had higher contrast? (1 or 2)&#39;</span>)</a></code></pre></div>
<p><img src="img/figure1.png" /></p>
<p>There seems to be a trend in the data: the larger the contrast in the first interval, the more likely the subject was to press the ‘1’ button. That’s a reasonable thing to do, but it’s hard to see and hard to quantify in this form. Instead, we will transform this data into a plot in which the independent variable is the contrast in interval 1 and the dependent variable is the proportion of trials for which the subject pressed the ‘1’ key for each contrast. Let’s define a function that will do that for us:</p>
<div class="sourceCode" id="cb3"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb3-1" data-line-number="1"></a>
<a class="sourceLine" id="cb3-2" data-line-number="2"><span class="kw">def</span> transform_data(data):</a>
<a class="sourceLine" id="cb3-3" data-line-number="3">    <span class="co">&quot;&quot;&quot;</span></a>
<a class="sourceLine" id="cb3-4" data-line-number="4"><span class="co">    Function that takes experimental data and gives us the dependent/independent</span></a>
<a class="sourceLine" id="cb3-5" data-line-number="5"><span class="co">    variables for analysis</span></a>
<a class="sourceLine" id="cb3-6" data-line-number="6"></a>
<a class="sourceLine" id="cb3-7" data-line-number="7"><span class="co">    Parameters</span></a>
<a class="sourceLine" id="cb3-8" data-line-number="8"><span class="co">    ----------</span></a>
<a class="sourceLine" id="cb3-9" data-line-number="9"><span class="co">    data : rec array</span></a>
<a class="sourceLine" id="cb3-10" data-line-number="10"><span class="co">        The data with records: `contrast1`, `contrast2` and `answer`</span></a>
<a class="sourceLine" id="cb3-11" data-line-number="11"></a>
<a class="sourceLine" id="cb3-12" data-line-number="12"><span class="co">    Returns</span></a>
<a class="sourceLine" id="cb3-13" data-line-number="13"><span class="co">    -------</span></a>
<a class="sourceLine" id="cb3-14" data-line-number="14"><span class="co">    x : The unique contrast differences.</span></a>
<a class="sourceLine" id="cb3-15" data-line-number="15"><span class="co">    y : The proportion of &#39;1&#39; answers in each contrast difference</span></a>
<a class="sourceLine" id="cb3-16" data-line-number="16"><span class="co">    n : The number of trials in each x,y condition</span></a>
<a class="sourceLine" id="cb3-17" data-line-number="17"><span class="co">    &quot;&quot;&quot;</span></a>
<a class="sourceLine" id="cb3-18" data-line-number="18">    x <span class="op">=</span> np.unique(data[<span class="st">&quot;contrast1&quot;</span>])</a>
<a class="sourceLine" id="cb3-19" data-line-number="19">    y <span class="op">=</span> []</a>
<a class="sourceLine" id="cb3-20" data-line-number="20">    n <span class="op">=</span> []</a>
<a class="sourceLine" id="cb3-21" data-line-number="21"></a>
<a class="sourceLine" id="cb3-22" data-line-number="22">    <span class="cf">for</span> c <span class="kw">in</span> x:</a>
<a class="sourceLine" id="cb3-23" data-line-number="23">        sub <span class="op">=</span> data[data[<span class="st">&quot;contrast1&quot;</span>] <span class="op">==</span> c]</a>
<a class="sourceLine" id="cb3-24" data-line-number="24">        n.append(sub.shape[<span class="dv">0</span>])</a>
<a class="sourceLine" id="cb3-25" data-line-number="25">        y.append(<span class="bu">sum</span>(sub[<span class="st">&quot;answer&quot;</span>] <span class="op">==</span> <span class="dv">1</span>) <span class="op">/</span> n[<span class="op">-</span><span class="dv">1</span>])</a>
<a class="sourceLine" id="cb3-26" data-line-number="26"></a>
<a class="sourceLine" id="cb3-27" data-line-number="27">    <span class="cf">return</span> x,y,n</a></code></pre></div>
<p>We separately transform the data into proportions for each one of the data files:</p>
<div class="sourceCode" id="cb4"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb4-1" data-line-number="1"></a>
<a class="sourceLine" id="cb4-2" data-line-number="2">x_ortho, y_ortho, n_ortho <span class="op">=</span> transform_data(ortho)</a>
<a class="sourceLine" id="cb4-3" data-line-number="3">x_para, y_para, n_para <span class="op">=</span> transform_data(para)</a></code></pre></div>
<p>And visualize that:</p>
<div class="sourceCode" id="cb5"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb5-1" data-line-number="1"></a>
<a class="sourceLine" id="cb5-2" data-line-number="2">fig, ax <span class="op">=</span> plt.subplots(<span class="dv">1</span>)</a>
<a class="sourceLine" id="cb5-3" data-line-number="3"><span class="co"># To plot each point with size proportional to the number of trials in that condition:</span></a>
<a class="sourceLine" id="cb5-4" data-line-number="4"><span class="cf">for</span> x,y,n <span class="kw">in</span> <span class="bu">zip</span>(x_ortho, y_ortho, n_ortho):</a>
<a class="sourceLine" id="cb5-5" data-line-number="5">    ax.plot(x, y, <span class="st">&#39;bo&#39;</span>, markersize<span class="op">=</span>n)</a>
<a class="sourceLine" id="cb5-6" data-line-number="6"></a>
<a class="sourceLine" id="cb5-7" data-line-number="7"><span class="cf">for</span> x,y,n <span class="kw">in</span> <span class="bu">zip</span>(x_para, y_para, n_para):</a>
<a class="sourceLine" id="cb5-8" data-line-number="8">    ax.plot(x, y, <span class="st">&#39;go&#39;</span>, markersize<span class="op">=</span>n)</a>
<a class="sourceLine" id="cb5-9" data-line-number="9"></a>
<a class="sourceLine" id="cb5-10" data-line-number="10">ax.set_xlabel(<span class="st">&#39;Contrast in interval 1&#39;</span>)</a>
<a class="sourceLine" id="cb5-11" data-line-number="11">ax.set_ylabel(<span class="st">&#39;Proportion answers `1`&#39;</span>)</a>
<a class="sourceLine" id="cb5-12" data-line-number="12">ax.set_ylim([<span class="op">-</span><span class="fl">0.1</span>, <span class="fl">1.1</span>])</a>
<a class="sourceLine" id="cb5-13" data-line-number="13">ax.set_xlim([<span class="op">-</span><span class="fl">0.1</span>, <span class="fl">1.1</span>])</a>
<a class="sourceLine" id="cb5-14" data-line-number="14">ax.grid(<span class="st">&#39;on&#39;</span>)</a>
<a class="sourceLine" id="cb5-15" data-line-number="15">fig.set_size_inches([<span class="dv">8</span>,<span class="dv">8</span>])</a></code></pre></div>
<p><img src="img/figure2.png" /></p>
<p>Obviously there is a systematic relationship between the contrast and the chances that this subject thought that the first interval had the higher contrast. For example, when the contrast was much higher in interval 1 ( e.g. 0.9), this person never said that the second interval had higher contrast. Likewise, when the contrast was very low, this person almost never said that the contrast in interval 1 had been higher. In the middle, there seems to be a monotonic relationship between the variables. Also, notice that the two sets of data (orthogonal and parallel) seem to be slightly different.</p>
<p>Can we say something more precise? For example, we might be interested in the contrast for which answers of ‘1’ and answers of ‘2’ are equally likely. This is known as the point of subjective equality (or PSE) and we can use it to compare different conditions in this experiment and in other experiments, compare different participants, etc.</p>
<p>In order to derive this quantity, or other quantities we approximate the data with a continuous function. Given this function, we can ask what is the x value of the function that corresponds to a y of exactly 0.5? This function is what we will call here a “model”. These functions usually describe the relationship between dependent and independent variables through a set of some other variables that we will call “model parameters”. The computational process of finding the values of the paramters that provide values of the model that most accurately approximate the data is what we will call “model fitting”.</p>
<aside class="callout panel panel-info">
<div class="panel-heading">
<h2 id="a-caveat-about-this-data"><span class="glyphicon glyphicon-pushpin"></span>A caveat about this data</h2>
</div>
<div class="panel-body">
<p>If were doing this in earnest, we would take into account the number of trials that was performed at each contrast (especially given that there are more trials in some conditions). For the purpose of this lesson, we will ignore that, and leave it as an exercise for the reader: to extend the methods shown here to account for these differences.</p>
</div>
</aside>
<h3 id="why-do-we-like-models">Why do we like models?</h3>
<p>Models derived from data are useful for several reasons:</p>
<ul>
<li><p><strong>They allow you to explain the data you have</strong>: summary statistics of the data, such as the mean of some variable, or the variance of this variable, are often not the best explanation of the data you have observed, in terms of the theory. For example, in the data we have observed in our experiment, a useful quantity is the PSE, which tells us what the perceived contrast of the surrounding grating was. This quantity is not readily present in summary statistics of the data. A functional form of a model is a mathematical formula that relates systematic changes in measured dependent variables, based on experimental manipulations of the independent variables. The functional form of the model varies with changes in model parameters. In the typical case, parameters are variables specificied in the model, that are neither your dependent variables nor your independent variables. If the model parameters correspond to theoretically meaningful quantities (such as the PSE), that can make the model useful in explaining the data and help test hypotheses about the theory behind the experiment.</p></li>
<li><p><strong>They allow you to predict data you haven’t collected</strong>: In many cases, assuming that the parameters don’t change with changes in the independent variables, models allow us to interpolate and predict what the dependent variables would have been like in other values of the independent variables. Even extrapolate to conditions that have not measured. For example, because measuring in these conditions is difficult for practical reasons.</p></li>
<li><p><strong>They allow us to build theories</strong>: By applying a modeling approach to data, we can hope to build an incremental knowledge abouth the domain we are studying. For example, Newton’s law of gravitation provides us with a quantitative prediction on the behavior of any two bodies. The observation that this model does not perform well in all conditions, led to Einstein’s theory of general relativity, which provides a generalization of this law (or model).</p></li>
</ul>
<section class="challenge panel panel-success">
<div class="panel-heading">
<h2 id="modeling-in-your-field"><span class="glyphicon glyphicon-pencil"></span>Modeling in your field</h2>
</div>
<div class="panel-body">
<p>Give an example of data that you use in your research and a model applied to the data.</p>
</div>
</section>
<p>In the following two sections, we will separately discuss linear models, and contrast these with non-linear models.</p>
<p><a href="02-linear-models.html">Click here for the next section</a>.</p>
        </div>
      </div>
      </article>
      <div class="footer">
        <a class="label swc-blue-bg" href="https://github.com/arokem/scipy-optimize">Source</a>
        <a class="label swc-blue-bg" href="mailto:arokem@gmail.com">Contact</a>
        <a class="label swc-blue-bg" href="LICENSE.html">License</a>
      </div>
    </div>
    <!-- Javascript placed at the end of the document so the pages load faster -->
    <script src="http://software-carpentry.org/v5/js/jquery-1.9.1.min.js"></script>
    <script src="css/bootstrap/bootstrap-js/bootstrap.js"></script>
    <script src='https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML'></script>
  </body>
</html>
